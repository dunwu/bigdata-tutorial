(window.webpackJsonp=window.webpackJsonp||[]).push([[37],{469:function(t,a,e){"use strict";e.r(a);var s=e(20),r=Object(s.a)({},(function(){var t=this,a=t.$createElement,e=t._self._c||a;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h1",{attrs:{id:"hive-入门"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#hive-入门"}},[t._v("#")]),t._v(" Hive 入门")]),t._v(" "),e("h2",{attrs:{id:"一、简介"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#一、简介"}},[t._v("#")]),t._v(" 一、简介")]),t._v(" "),e("p",[t._v("Hive 是一个构建在 Hadoop 之上的数据仓库，它可以将结构化的数据文件映射成表，并提供类 SQL 查询功能，用于查询的 SQL 语句会被转化为 MapReduce 作业，然后提交到 Hadoop 上运行。")]),t._v(" "),e("p",[e("strong",[t._v("特点")]),t._v("：")]),t._v(" "),e("ol",[e("li",[t._v("简单、容易上手 (提供了类似 sql 的查询语言 hql)，使得精通 sql 但是不了解 Java 编程的人也能很好地进行大数据分析；")]),t._v(" "),e("li",[t._v("灵活性高，可以自定义用户函数 (UDF) 和存储格式；")]),t._v(" "),e("li",[t._v("为超大的数据集设计的计算和存储能力，集群扩展容易;")]),t._v(" "),e("li",[t._v("统一的元数据管理，可与 presto／impala／sparksql 等共享数据；")]),t._v(" "),e("li",[t._v("执行延迟高，不适合做数据的实时处理，但适合做海量数据的离线处理。")])]),t._v(" "),e("h2",{attrs:{id:"二、hive-的体系架构"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#二、hive-的体系架构"}},[t._v("#")]),t._v(" 二、Hive 的体系架构")]),t._v(" "),e("p",[e("img",{attrs:{src:"https://raw.githubusercontent.com/dunwu/images/dev/snap/20200224193019.png",alt:"img"}})]),t._v(" "),e("h3",{attrs:{id:"command-line-shell-thrift-jdbc"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#command-line-shell-thrift-jdbc"}},[t._v("#")]),t._v(" command-line shell & thrift/jdbc")]),t._v(" "),e("p",[t._v("可以用 command-line shell 和 thrift／jdbc 两种方式来操作数据：")]),t._v(" "),e("ul",[e("li",[e("strong",[t._v("command-line shell")]),t._v("：通过 hive 命令行的的方式来操作数据；")]),t._v(" "),e("li",[e("strong",[t._v("thrift／jdbc")]),t._v("：通过 thrift 协议按照标准的 JDBC 的方式操作数据。")])]),t._v(" "),e("h3",{attrs:{id:"metastore"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#metastore"}},[t._v("#")]),t._v(" Metastore")]),t._v(" "),e("p",[t._v("在 Hive 中，表名、表结构、字段名、字段类型、表的分隔符等统一被称为元数据。所有的元数据默认存储在 Hive 内置的 derby 数据库中，但由于 derby 只能有一个实例，也就是说不能有多个命令行客户端同时访问，所以在实际生产环境中，通常使用 MySQL 代替 derby。")]),t._v(" "),e("p",[t._v("Hive 进行的是统一的元数据管理，就是说你在 Hive 上创建了一张表，然后在 presto／impala／sparksql 中都是可以直接使用的，它们会从 Metastore 中获取统一的元数据信息，同样的你在 presto／impala／sparksql 中创建一张表，在 Hive 中也可以直接使用。")]),t._v(" "),e("h3",{attrs:{id:"hql-的执行流程"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#hql-的执行流程"}},[t._v("#")]),t._v(" HQL 的执行流程")]),t._v(" "),e("p",[t._v("Hive 在执行一条 HQL 的时候，会经过以下步骤：")]),t._v(" "),e("ol",[e("li",[t._v("语法解析：Antlr 定义 SQL 的语法规则，完成 SQL 词法，语法解析，将 SQL 转化为抽象 语法树 AST Tree；")]),t._v(" "),e("li",[t._v("语义解析：遍历 AST Tree，抽象出查询的基本组成单元 QueryBlock；")]),t._v(" "),e("li",[t._v("生成逻辑执行计划：遍历 QueryBlock，翻译为执行操作树 OperatorTree；")]),t._v(" "),e("li",[t._v("优化逻辑执行计划：逻辑层优化器进行 OperatorTree 变换，合并不必要的 ReduceSinkOperator，减少 shuffle 数据量；")]),t._v(" "),e("li",[t._v("生成物理执行计划：遍历 OperatorTree，翻译为 MapReduce 任务；")]),t._v(" "),e("li",[t._v("优化物理执行计划：物理层优化器进行 MapReduce 任务的变换，生成最终的执行计划。")])]),t._v(" "),e("blockquote",[e("p",[t._v("关于 Hive SQL 的详细执行流程可以参考美团技术团队的文章："),e("a",{attrs:{href:"https://tech.meituan.com/2014/02/12/hive-sql-to-mapreduce.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("Hive SQL 的编译过程"),e("OutboundLink")],1)])]),t._v(" "),e("h2",{attrs:{id:"三、数据类型"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#三、数据类型"}},[t._v("#")]),t._v(" 三、数据类型")]),t._v(" "),e("h3",{attrs:{id:"基本数据类型"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#基本数据类型"}},[t._v("#")]),t._v(" 基本数据类型")]),t._v(" "),e("p",[t._v("Hive 表中的列支持以下基本数据类型：")]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",[t._v("大类")]),t._v(" "),e("th",[t._v("类型")])])]),t._v(" "),e("tbody",[e("tr",[e("td",[e("strong",[t._v("Integers（整型）")])]),t._v(" "),e("td",[t._v("TINYINT—1 字节的有符号整数 "),e("br"),t._v("SMALLINT—2 字节的有符号整数"),e("br"),t._v(" INT—4 字节的有符号整数"),e("br"),t._v(" BIGINT—8 字节的有符号整数")])]),t._v(" "),e("tr",[e("td",[e("strong",[t._v("Boolean（布尔型）")])]),t._v(" "),e("td",[t._v("BOOLEAN—TRUE/FALSE")])]),t._v(" "),e("tr",[e("td",[e("strong",[t._v("Floating point numbers（浮点型）")])]),t._v(" "),e("td",[t._v("FLOAT— 单精度浮点型 "),e("br"),t._v("DOUBLE—双精度浮点型")])]),t._v(" "),e("tr",[e("td",[e("strong",[t._v("Fixed point numbers（定点数）")])]),t._v(" "),e("td",[t._v("DECIMAL—用户自定义精度定点数，比如 DECIMAL(7,2)")])]),t._v(" "),e("tr",[e("td",[e("strong",[t._v("String types（字符串）")])]),t._v(" "),e("td",[t._v("STRING—指定字符集的字符序列"),e("br"),t._v(" VARCHAR—具有最大长度限制的字符序列 "),e("br"),t._v("CHAR—固定长度的字符序列")])]),t._v(" "),e("tr",[e("td",[e("strong",[t._v("Date and time types（日期时间类型）")])]),t._v(" "),e("td",[t._v("TIMESTAMP — 时间戳 "),e("br"),t._v("TIMESTAMP WITH LOCAL TIME ZONE — 时间戳，纳秒精度"),e("br"),t._v(" DATE—日期类型")])]),t._v(" "),e("tr",[e("td",[e("strong",[t._v("Binary types（二进制类型）")])]),t._v(" "),e("td",[t._v("BINARY—字节序列")])])])]),t._v(" "),e("blockquote",[e("p",[t._v("TIMESTAMP 和 TIMESTAMP WITH LOCAL TIME ZONE 的区别如下：")]),t._v(" "),e("ul",[e("li",[e("strong",[t._v("TIMESTAMP WITH LOCAL TIME ZONE")]),t._v("：用户提交时间给数据库时，会被转换成数据库所在的时区来保存。查询时则按照查询客户端的不同，转换为查询客户端所在时区的时间。")]),t._v(" "),e("li",[e("strong",[t._v("TIMESTAMP")]),t._v(" ：提交什么时间就保存什么时间，查询时也不做任何转换。")])])]),t._v(" "),e("h3",{attrs:{id:"隐式转换"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#隐式转换"}},[t._v("#")]),t._v(" 隐式转换")]),t._v(" "),e("p",[t._v("Hive 中基本数据类型遵循以下的层次结构，按照这个层次结构，子类型到祖先类型允许隐式转换。例如 INT 类型的数据允许隐式转换为 BIGINT 类型。额外注意的是：按照类型层次结构允许将 STRING 类型隐式转换为 DOUBLE 类型。")]),t._v(" "),e("p",[e("img",{attrs:{src:"https://raw.githubusercontent.com/dunwu/images/dev/snap/20200224193613.png",alt:"img"}})]),t._v(" "),e("h3",{attrs:{id:"复杂类型"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#复杂类型"}},[t._v("#")]),t._v(" 复杂类型")]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",[t._v("类型")]),t._v(" "),e("th",[t._v("描述")]),t._v(" "),e("th",[t._v("示例")])])]),t._v(" "),e("tbody",[e("tr",[e("td",[e("strong",[t._v("STRUCT")])]),t._v(" "),e("td",[t._v("类似于对象，是字段的集合，字段的类型可以不同，可以使用 "),e("code",[t._v("名称.字段名")]),t._v(" 方式进行访问")]),t._v(" "),e("td",[t._v("STRUCT ('xiaoming', 12 , '2018-12-12')")])]),t._v(" "),e("tr",[e("td",[e("strong",[t._v("MAP")])]),t._v(" "),e("td",[t._v("键值对的集合，可以使用 "),e("code",[t._v("名称[key]")]),t._v(" 的方式访问对应的值")]),t._v(" "),e("td",[t._v("map('a', 1, 'b', 2)")])]),t._v(" "),e("tr",[e("td",[e("strong",[t._v("ARRAY")])]),t._v(" "),e("td",[t._v("数组是一组具有相同类型和名称的变量的集合，可以使用 "),e("code",[t._v("名称[index]")]),t._v(" 访问对应的值")]),t._v(" "),e("td",[t._v("ARRAY('a', 'b', 'c', 'd')")])])])]),t._v(" "),e("h3",{attrs:{id:"示例"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#示例"}},[t._v("#")]),t._v(" 示例")]),t._v(" "),e("p",[t._v("如下给出一个基本数据类型和复杂数据类型的使用示例：")]),t._v(" "),e("div",{staticClass:"language-sql extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sql"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CREATE")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" students"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  name      STRING"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("   "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 姓名")]),t._v("\n  age       "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INT")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("      "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 年龄")]),t._v("\n  subject   ARRAY"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("STRING"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("   "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("--学科")]),t._v("\n  score     MAP"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("STRING"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FLOAT")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("--各个学科考试成绩")]),t._v("\n  address   STRUCT"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("houseNumber:"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" street:STRING"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" city:STRING"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" province：STRING"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("--家庭居住地址")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ROW")]),t._v(" FORMAT DELIMITED "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FIELDS")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TERMINATED")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BY")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\t"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),e("h2",{attrs:{id:"四、内容格式"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#四、内容格式"}},[t._v("#")]),t._v(" 四、内容格式")]),t._v(" "),e("p",[t._v("当数据存储在文本文件中，必须按照一定格式区别行和列，如使用逗号作为分隔符的 CSV 文件 (Comma-Separated Values) 或者使用制表符作为分隔值的 TSV 文件 (Tab-Separated Values)。但此时也存在一个缺点，就是正常的文件内容中也可能出现逗号或者制表符。")]),t._v(" "),e("p",[t._v("所以 Hive 默认使用了几个平时很少出现的字符，这些字符一般不会作为内容出现在文件中。Hive 默认的行和列分隔符如下表所示。")]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",[t._v("分隔符")]),t._v(" "),e("th",[t._v("描述")])])]),t._v(" "),e("tbody",[e("tr",[e("td",[e("strong",[t._v("\\n")])]),t._v(" "),e("td",[t._v("对于文本文件来说，每行是一条记录，所以可以使用换行符来分割记录")])]),t._v(" "),e("tr",[e("td",[e("strong",[t._v("^A (Ctrl+A)")])]),t._v(" "),e("td",[t._v("分割字段 (列)，在 CREATE TABLE 语句中也可以使用八进制编码 "),e("code",[t._v("\\001")]),t._v(" 来表示")])]),t._v(" "),e("tr",[e("td",[e("strong",[t._v("^B")])]),t._v(" "),e("td",[t._v("用于分割 ARRAY 或者 STRUCT 中的元素，或者用于 MAP 中键值对之间的分割，"),e("br"),t._v("在 CREATE TABLE 语句中也可以使用八进制编码 "),e("code",[t._v("\\002")]),t._v(" 表示")])]),t._v(" "),e("tr",[e("td",[e("strong",[t._v("^C")])]),t._v(" "),e("td",[t._v("用于 MAP 中键和值之间的分割，在 CREATE TABLE 语句中也可以使用八进制编码 "),e("code",[t._v("\\003")]),t._v(" 表示")])])])]),t._v(" "),e("p",[t._v("使用示例如下：")]),t._v(" "),e("div",{staticClass:"language-sql extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sql"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CREATE")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" page_view"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("viewTime "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INT")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" userid "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BIGINT")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ROW")]),t._v(" FORMAT DELIMITED\n   "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FIELDS")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TERMINATED")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BY")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'\\001'")]),t._v("\n   COLLECTION ITEMS "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TERMINATED")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BY")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'\\002'")]),t._v("\n   MAP "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("KEYS")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TERMINATED")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BY")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'\\003'")]),t._v("\n STORED "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" SEQUENCEFILE"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),e("h2",{attrs:{id:"五、存储格式"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#五、存储格式"}},[t._v("#")]),t._v(" 五、存储格式")]),t._v(" "),e("h3",{attrs:{id:"支持的存储格式"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#支持的存储格式"}},[t._v("#")]),t._v(" 支持的存储格式")]),t._v(" "),e("p",[t._v("Hive 会在 HDFS 为每个数据库上创建一个目录，数据库中的表是该目录的子目录，表中的数据会以文件的形式存储在对应的表目录下。Hive 支持以下几种文件存储格式：")]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",[t._v("格式")]),t._v(" "),e("th",[t._v("说明")])])]),t._v(" "),e("tbody",[e("tr",[e("td",[e("strong",[t._v("TextFile")])]),t._v(" "),e("td",[t._v("存储为纯文本文件。 这是 Hive 默认的文件存储格式。这种存储方式数据不做压缩，磁盘开销大，数据解析开销大。")])]),t._v(" "),e("tr",[e("td",[e("strong",[t._v("SequenceFile")])]),t._v(" "),e("td",[t._v("SequenceFile 是 Hadoop API 提供的一种二进制文件，它将数据以<key,value>的形式序列化到文件中。这种二进制文件内部使用 Hadoop 的标准的 Writable 接口实现序列化和反序列化。它与 Hadoop API 中的 MapFile 是互相兼容的。Hive 中的 SequenceFile 继承自 Hadoop API 的 SequenceFile，不过它的 key 为空，使用 value 存放实际的值，这样是为了避免 MR 在运行 map 阶段进行额外的排序操作。")])]),t._v(" "),e("tr",[e("td",[e("strong",[t._v("RCFile")])]),t._v(" "),e("td",[t._v("RCFile 文件格式是 FaceBook 开源的一种 Hive 的文件存储格式，首先将表分为几个行组，对每个行组内的数据按列存储，每一列的数据都是分开存储。")])]),t._v(" "),e("tr",[e("td",[e("strong",[t._v("ORC Files")])]),t._v(" "),e("td",[t._v("ORC 是在一定程度上扩展了 RCFile，是对 RCFile 的优化。")])]),t._v(" "),e("tr",[e("td",[e("strong",[t._v("Avro Files")])]),t._v(" "),e("td",[t._v("Avro 是一个数据序列化系统，设计用于支持大批量数据交换的应用。它的主要特点有：支持二进制序列化方式，可以便捷，快速地处理大量数据；动态语言友好，Avro 提供的机制使动态语言可以方便地处理 Avro 数据。")])]),t._v(" "),e("tr",[e("td",[e("strong",[t._v("Parquet")])]),t._v(" "),e("td",[t._v("Parquet 是基于 Dremel 的数据模型和算法实现的，面向分析型业务的列式存储格式。它通过按列进行高效压缩和特殊的编码技术，从而在降低存储空间的同时提高了 IO 效率。")])])])]),t._v(" "),e("blockquote",[e("p",[t._v("以上压缩格式中 ORC 和 Parquet 的综合性能突出，使用较为广泛，推荐使用这两种格式。")])]),t._v(" "),e("h3",{attrs:{id:"指定存储格式"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#指定存储格式"}},[t._v("#")]),t._v(" 指定存储格式")]),t._v(" "),e("p",[t._v("通常在创建表的时候使用 "),e("code",[t._v("STORED AS")]),t._v(" 参数指定：")]),t._v(" "),e("div",{staticClass:"language-sql extra-class"},[e("pre",{pre:!0,attrs:{class:"language-sql"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CREATE")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" page_view"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("viewTime "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INT")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" userid "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BIGINT")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ROW")]),t._v(" FORMAT DELIMITED\n   "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FIELDS")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TERMINATED")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BY")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'\\001'")]),t._v("\n   COLLECTION ITEMS "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TERMINATED")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BY")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'\\002'")]),t._v("\n   MAP "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("KEYS")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TERMINATED")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BY")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'\\003'")]),t._v("\n STORED "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" SEQUENCEFILE"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),e("p",[t._v("各个存储文件类型指定方式如下：")]),t._v(" "),e("ul",[e("li",[t._v("STORED AS TEXTFILE")]),t._v(" "),e("li",[t._v("STORED AS SEQUENCEFILE")]),t._v(" "),e("li",[t._v("STORED AS ORC")]),t._v(" "),e("li",[t._v("STORED AS PARQUET")]),t._v(" "),e("li",[t._v("STORED AS AVRO")]),t._v(" "),e("li",[t._v("STORED AS RCFILE")])]),t._v(" "),e("h2",{attrs:{id:"六、内部表和外部表"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#六、内部表和外部表"}},[t._v("#")]),t._v(" 六、内部表和外部表")]),t._v(" "),e("p",[t._v("内部表又叫做管理表 (Managed/Internal Table)，创建表时不做任何指定，默认创建的就是内部表。想要创建外部表 (External Table)，则需要使用 External 进行修饰。 内部表和外部表主要区别如下：")]),t._v(" "),e("table",[e("thead",[e("tr",[e("th"),t._v(" "),e("th",[t._v("内部表")]),t._v(" "),e("th",[t._v("外部表")])])]),t._v(" "),e("tbody",[e("tr",[e("td",[t._v("数据存储位置")]),t._v(" "),e("td",[t._v("内部表数据存储的位置由 hive.metastore.warehouse.dir 参数指定，默认情况下表的数据存储在 HDFS 的 "),e("code",[t._v("/user/hive/warehouse/数据库名.db/表名/")]),t._v(" 目录下")]),t._v(" "),e("td",[t._v("外部表数据的存储位置创建表时由 "),e("code",[t._v("Location")]),t._v(" 参数指定；")])]),t._v(" "),e("tr",[e("td",[t._v("导入数据")]),t._v(" "),e("td",[t._v("在导入数据到内部表，内部表将数据移动到自己的数据仓库目录下，数据的生命周期由 Hive 来进行管理")]),t._v(" "),e("td",[t._v("外部表不会将数据移动到自己的数据仓库目录下，只是在元数据中存储了数据的位置")])]),t._v(" "),e("tr",[e("td",[t._v("删除表")]),t._v(" "),e("td",[t._v("删除元数据（metadata）和文件")]),t._v(" "),e("td",[t._v("只删除元数据（metadata）")])])])]),t._v(" "),e("h2",{attrs:{id:"参考资料"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#参考资料"}},[t._v("#")]),t._v(" 参考资料")]),t._v(" "),e("ul",[e("li",[e("a",{attrs:{href:"https://cwiki.apache.org/confluence/display/Hive/GettingStarted",target:"_blank",rel:"noopener noreferrer"}},[t._v("Hive Getting Started"),e("OutboundLink")],1)]),t._v(" "),e("li",[e("a",{attrs:{href:"https://tech.meituan.com/2014/02/12/hive-sql-to-mapreduce.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("Hive SQL 的编译过程"),e("OutboundLink")],1)]),t._v(" "),e("li",[e("a",{attrs:{href:"https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL",target:"_blank",rel:"noopener noreferrer"}},[t._v("LanguageManual DDL"),e("OutboundLink")],1)]),t._v(" "),e("li",[e("a",{attrs:{href:"https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Types",target:"_blank",rel:"noopener noreferrer"}},[t._v("LanguageManual Types"),e("OutboundLink")],1)]),t._v(" "),e("li",[e("a",{attrs:{href:"https://cwiki.apache.org/confluence/display/Hive/Managed+vs.+External+Tables",target:"_blank",rel:"noopener noreferrer"}},[t._v("Managed vs. External Tables"),e("OutboundLink")],1)])])])}),[],!1,null,null,null);a.default=r.exports}}]);